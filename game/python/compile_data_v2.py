import os
from pathlib import Path
from .helpers import (parse_markdown)

types = {
    "item": {},
    "character": {
        "class": "RPGCharacter"
    },
    "location": {},
    "inventory": {},
    "quest": {
        "headings": [
             { "name": "goals", "format_str": ".goal({arg_kwargs})" },
             { "name": "choices", "format_str": ".choice({arg_kwargs})" }
        ]
    },
    "stat": {},
    "faction": {},
    "slot": {},
    "body_type": {},
    "dialogue": {},
    "shop": {},
    "craft": {},
    "note": {},
    "achievement": {},
    "perk": {},
    "status_effect": {},
    "bond": {}
}

def compile_data():
    all_ids = {} # To test for collisions.
    data_consolidated = {k: {} for k in types.keys()}

    base_dir = Path(__file__).resolve().parents[2]
    data_dir = base_dir / "data"
    total_files = 0
    for md_file in data_dir.rglob("*.md"):
        md_data = md_file.read_text(encoding="utf-8")
        fm, heads = parse_markdown(md_data)
        if "type" in fm:
            obj_type = fm["type"]
            obj_id = fm.get("id") or fm.get("name", md_file.stem).lower().replace(" ", "_")
            if obj_type in types:
                if obj_id in all_ids:
                    print(f"Warning: Duplicate ID '{obj_id}' found in {md_file} (also in {all_ids[obj_id]})")
                all_ids[obj_id] = obj_type
                data_consolidated[obj_type][obj_id] = (fm, heads)
                total_files += 1
            else:
                print(f"Warning: Unknown type '{obj_type}' in {md_file}. Skipping.")
        else:
            print(f"Warning: No type specified in {md_file}. Skipping.")
    print(f"Processed {total_files} data files across {len(types)} types.")

    script = []
    script.append("# This file is auto-generated by compile_data_v2.py. Do not edit manually.")
    labels = []

    for type, type_data in types.items():
        type_class = type_data.get("class", type.capitalize()) # Assuming class names are capitalized versions of types
        script.append(f"\n# --- {type.upper()} x{len(data_consolidated[type])} ---")
        defaults = []
        defines = [f"define all_{type}s = ["]
        labels.append(f"label {type}:")
        for obj_id, obj_data in data_consolidated[type].items():
            obj_data, obj_heads = obj_data
            kwarg_str = ", ".join(f"{k}={repr(v)}" for k, v in obj_data.items() if k not in ["id", "type"])
            defaults.append(f'default {obj_id} = {type_class}("{obj_id}", {kwarg_str})')
            defines.append(f'    "{obj_id}" = {obj_id},')
            labels.append(f"    label .{obj_id}:")

            for head_id, head_data in obj_heads.items():
                codeblocks = head_data.get("codeblocks", [])
                for codeblock in codeblocks:
                    if codeblock["language"] == "flow":
                        label_suffix = head_data['name'].replace(" ", "_").lower()
                        labels.append(f"        label .{label_suffix}:")
                        labels.append("            " + codeblock["parsed"].replace("\n", "\n            "))
                        labels.append(f"            return")
                    elif codeblock["language"] == "yaml":
                        yaml_data = codeblock["parsed"]
                        if "type" in yaml_data:
                            subtype_id = obj_id + "__" + head_data["name"].replace(" ", "_").lower()
                            yaml_args = ", ".join(f"{k}={repr(v)}" for k, v in yaml_data.items() if k not in ["type"])
                            defaults[-1] += "\\"
                            defaults.append(f'    .add_{yaml_data["type"]}("{subtype_id}", {yaml_args})')
                        else:
                            print(f"Warning: YAML codeblock in {obj_id}#{head_id} is missing 'type'. Skipping.")
            
            labels.append(f"        return")
        labels.append(f"    return")

        defines.append("]")
        script += defaults + defines

    script.append(f"\n# --- LABELS x{len(labels)} ---")
    script += labels

    rpy_output_file = base_dir / "game" / "generated" / "autogenerated_dont_edit.rpy"
    with rpy_output_file.open("w", encoding="utf-8") as f:
        f.write("\n".join(script))
    print(f"RPY definitions written to {rpy_output_file}")

compile_data()